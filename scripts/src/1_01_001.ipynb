{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2c65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../../\") # go to parent dir from customFunctions import *\n",
    "import statbot_helpers as sbh\n",
    "from pyaxis import pyaxis\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c4a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfs_nr of dataset\n",
    "BFS_NR = 'px-x-0102010000_101'\n",
    "\n",
    "STICHTAG =  '-10-18' # -%m-%d\n",
    "\n",
    "# get asset_nr\n",
    "asset_nr = sbh.get_bfs_asset_nr(BFS_NR)\n",
    "BFS_URL = \"https://www.bfs.admin.ch/bfsstatic/dam/assets/\" + str(asset_nr) + \"/master\"\n",
    "\n",
    "# load data from bfs\n",
    "px = pyaxis.parse(BFS_URL, encoding='ISO-8859-2')\n",
    "\n",
    "# clean df\n",
    "df = px['DATA'].loc[px['DATA']['Bevölkerungstyp'] == 'Ständige Wohnbevölkerung']\n",
    "df = df.drop(columns=['Bevölkerungstyp'])\n",
    "df = df.rename(columns={\"Kanton (-) / Bezirk (>>) / Gemeinde (......)\": \"name\"})\n",
    "\n",
    "\n",
    "# add column with spatialunit_ontology\n",
    "df.loc[df['name'].str.startswith(\"......\"), \"spatialunit_ontology\"] = \"A.ADM3\"\n",
    "#df.loc[df['name'].str.startswith(\">>\"), \"spatialunit_ontology\"] = \"A.ADM2\"\n",
    "#df.loc[df['name'].str.startswith(\"-\"), \"spatialunit_ontology\"] = \"A.ADM1\"\n",
    "#df.loc[df['name'].str.startswith(\"Schweiz\"), \"spatialunit_ontology\"] = \"CH\"\n",
    "\n",
    "df = df.dropna(subset=['spatialunit_ontology'])\n",
    "\n",
    "df['spatialunit_ontology'] = df['spatialunit_ontology'].astype('category') # reduce memory footprint\n",
    "\n",
    "\n",
    "# extract bfs_nr and name for gemeinde\n",
    "df.loc[df['spatialunit_ontology'] == 'A.ADM3', 'bfs_nr'] = df['name'].str.slice(6,11)\n",
    "df.loc[df['spatialunit_ontology'] == 'A.ADM3', 'name'] = df['name'].str.slice(11)\n",
    "\n",
    "df['bfs_nr'] = df['bfs_nr'].astype('int16')\n",
    "\n",
    "# extract name for bezirk\n",
    "#df.loc[df['spatialunit_ontology'] == 'A.ADM2', 'name'] = df['name'].str.slice(3)\n",
    "\n",
    "# extract name for kanton\n",
    "#df.loc[df['spatialunit_ontology'] == 'A.ADM1', 'name'] = df['name'].str.slice(2)\n",
    "\n",
    "# convert origin\n",
    "df.loc[df['Staatsangehörigkeit (Kategorie)'] == 'Staatsangehörigkeit (Kategorie) - Total', 'Staatsangehörigkeit (Kategorie)'] = '-1'\n",
    "df.loc[df['Staatsangehörigkeit (Kategorie)'] == 'Schweiz', 'Staatsangehörigkeit (Kategorie)'] = '1'\n",
    "df.loc[df['Staatsangehörigkeit (Kategorie)'] == 'Ausland', 'Staatsangehörigkeit (Kategorie)'] = '2'\n",
    "\n",
    "# convert sex\n",
    "df.loc[df['Geschlecht'] == 'Geschlecht - Total', 'Geschlecht'] = '-1'\n",
    "df.loc[df['Geschlecht'] == 'Mann', 'Geschlecht'] = '1'\n",
    "df.loc[df['Geschlecht'] == 'Frau', 'Geschlecht'] = '2'\n",
    "\n",
    "df['Geschlecht'] = df['Geschlecht'].astype('category') # reduce memory footprint\n",
    "\n",
    "\n",
    "# convert age\n",
    "df['Alter'] = df['Alter'].str.split(\" \", n=1, expand=True)[0]\n",
    "df.loc[df['Alter'] == 'Alter', 'Alter'] = '-1'\n",
    "\n",
    "df['DATA'] = df['DATA'].astype('int32')\n",
    "df['Alter'] = df['Alter'].astype('int16')\n",
    "\n",
    "df['Jahr'] += STICHTAG\n",
    "\n",
    "df['period_value'] = np.NAN\n",
    "\n",
    "df.columns = ['time_value', 'spatialunit_name', 'origin', 'sex', 'age', \n",
    "              'value', 'spatialunit_ontology', 'spatialunit_current_id', 'period_value']\n",
    "\n",
    "df = df[['spatialunit_ontology', 'spatialunit_name', \n",
    "         'time_value', 'period_value', 'value', 'origin', 'sex', 'age', 'spatialunit_current_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc983c33-810f-49b4-a89d-1455fafbe92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.head(100000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b14207-6a42-482c-ad11-22a8c9ead5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = sbh.convert_current_to_hist_id(test, '2021-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af871c-c2b1-4790-a3e4-14f3dc383c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try = df_clean.head(50000)\n",
    "df_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ea659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_granularity_levels_up(df,list_ontologies):\n",
    "\n",
    "list_ontologies = ['A.ADM2', 'A.ADM1', 'CH']\n",
    "\n",
    "spatial_unit_table = pd.read_csv(\"/home/b105p02@ji.ktzh.ch/gitrepos/statbot/data/spatialunits.csv\", \n",
    "                                 usecols=[\"spatialunit_ontology\",\"spatialunit_hist_id\",\"canton_hist_id\",\"district_hist_id\"])\n",
    "\n",
    "spatial_unit_table[['canton_hist_id', 'district_hist_id']] = spatial_unit_table[['canton_hist_id', 'district_hist_id']].astype('Int64')\n",
    "\n",
    "\n",
    "df_try_out = df_try.copy()\n",
    "\n",
    "df_try = df_try[df_try['spatialunit_ontology'] == 'A.ADM3']\n",
    "\n",
    "df_try = pd.merge(df_try, spatial_unit_table, how='left', on=['spatialunit_ontology', 'spatialunit_hist_id'])\n",
    "\n",
    "\n",
    "if 'A.ADM2' in list_ontologies:\n",
    "    list_to_group = [\"district_hist_id\",\"time_value\"]\n",
    "    adm2 = df_try.groupby(by=list_to_group)['value'].sum()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statbot_env",
   "language": "python",
   "name": "statbot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
